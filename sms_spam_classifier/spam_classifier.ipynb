{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693dfff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2070eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/SMSSpamCollection'\n",
    "df = pd.read_table(data_path,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16ff26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['spam','message']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7833d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9eec347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removables from text\n",
    "stopwords_set=set(stopwords)\n",
    "punctuation_set=set(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f572b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>message</th>\n",
       "      <th>cleaned_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go jurong point, crazy.. Available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say early hor... U c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                            message  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                         cleaned_msg  \n",
       "0  Go jurong point, crazy.. Available bugis n gre...  \n",
       "1                      Ok lar... Joking wif u oni...  \n",
       "2  Free entry 2 wkly comp win FA Cup final tkts 2...  \n",
       "3          U dun say early hor... U c already say...  \n",
       "4          Nah I think goes usf, lives around though  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation and stopwords\n",
    "df['cleaned_msg'] = df.message.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords_set\n",
    "                                                        and word not in punctuation_set]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42427edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992a9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model with count vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b53f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6d5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text into tokens\n",
    "X = count_vect.fit_transform(df.cleaned_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d101258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e660ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8703) (5572,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,\n",
    "      y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405c2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47383c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0553bd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849246231155779"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.fit(X_train,y_train)\n",
    "y_pred =lg.predict(X_test)\n",
    "\n",
    "#test score\n",
    "lg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c7dd057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1219,    1],\n",
       "       [  20,  153]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_cv_mat = confusion_matrix(y_test,y_pred)\n",
    "lg_cv_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65cdef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e478d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regressor with tfidfvectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9a9b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9436e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df.cleaned_msg)\n",
    "y = df.spam\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e436fff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9569274946159368"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(X_train,y_train)\n",
    "y_pred =lg.predict(X_test)\n",
    "\n",
    "#test score\n",
    "lg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1be6b843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1204,    1],\n",
       "       [  59,  129]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_tfidf_mat = confusion_matrix(y_test,y_pred)\n",
    "lg_tfidf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4ae4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aea8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest modek with count vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe9a784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1119e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text into tokens\n",
    "X = count_vect.fit_transform(df.cleaned_msg)\n",
    "y = df.spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "997a3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a48d95da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9798994974874372"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4eaf1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1200,    0],\n",
       "       [  28,  165]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_mat = confusion_matrix(y_test,y_pred)\n",
    "rf_cv_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f9eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7e19c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model with tfidfvectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3146179",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92b39e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df.cleaned_msg)\n",
    "y = df.spam\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebdca7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755922469490309"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ef2a782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1211,    0],\n",
       "       [  34,  148]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tfidf_mat = confusion_matrix(y_test,y_pred)\n",
    "rf_tfidf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8444624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdbb0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
